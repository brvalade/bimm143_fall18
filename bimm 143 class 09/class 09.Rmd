---
title: "class 09"
author: "Brian Valadez"
date: "October 30, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Class 09
Downloading the data and removing the id and diagnosis from the data set.
```{r}
wisc.df <- read.csv("https://bioboot.github.io/bimm143_W18/class-material/WisconsinCancer.csv")
wisc.data <- as.matrix(wisc.df[3:32])

```
 Renaming the rows
```{r}
row.names(wisc.data) <- wisc.df$id
head(wisc.data)
```
```{r}
table (wisc.df$diagnosis)
diagnosis <- as.numeric(wisc.df$diagnosis=="M")
diagnosis
sum(diagnosis)
colnames(wisc.data)
grep(pattern = "mean", colnames(wisc.data))
length(grep(pattern = "mean", colnames(wisc.data)))
```
 
Q1. How many observations are in this dataset?
569
Q2. How many variables/features in the data are suffixed with _mean?
10
Q3. How many of the observations have a malignant diagnosis?
212
#Section 2 Performing PCA
```{r}
colMeans(wisc.data)
apply(wisc.data,2,sd)
scale.wisc.data <- scale(wisc.data)
wisc.pr <- prcomp(scale.wisc.data)
summary(wisc.pr)
```

Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
0.4427

Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
3
Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
7

#Interpreting PCA results
```{r}
biplot(wisc.pr)
```
What stands out to you about this plot? Is it easy or difficult to understand? Why?

Basiically everything is difficult to understand. Many of the words are overlapping making them to read and it is hard to distinguish the different data points.


#Making a PC1 V PC2 graph

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis+1,  xlab = "PC1", ylab = "PC2")
```

Q8. Repeat the same for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")
```

#Variance explained
```{r}
pr.var <-wisc.pr$sdev^2
sum(pr.var)
pve <- pr.var/30
 plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
pve
```
Doing a bar plot instead this time

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

Creating a plot with of cummulative proportion of variance

```{r}
wisc.plot.cum <- plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

wisc.plot.cum
```

Creating a side by side plot of the two graphs

```{r}
par(mfrow=c(1,2))
    
   plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
   
   plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
   
```


#Section 3 Hierarchical clustering of case data

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
plot(wisc.hclust)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```
#skipping section 4
#Section 5 Clustering on PCA results
```{r}
d.pr <- dist(wisc.pr$x[,1:7])
wisc.pr.hclust <- hclust(d.pr, method="complete")
plot(wisc.pr.hclust)

```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
table(wisc.pr.hclust.clusters, diagnosis)

```

